## 前端工程化

#### npm start和npm run dev区别
1. `npm start`
- **作用：** `npm start` 是 npm 的一个约定命令，用于启动项目或应用的主要入口点。通常用于生产环境或部署时启动应用。
- **约定：** 在大多数情况下，`npm start` 默认执行的是 `node server.js`，其中 `server.js` 是项目的主入口文件或者指定的启动脚本。
- **配置：** 如果项目的 `package.json` 文件中没有特别指定 `start` 脚本，那么默认情况下执行 `npm start` 会报错。
2. `npm run dev`
- **作用：** `npm run dev` 是一个自定义的 npm 命令，通常用于在开发过程中启动开发服务器或者执行开发环境相关的操作。
- **约定：** `npm run dev` 并没有特定的约定，它需要在项目的 `package.json` 文件中显式地定义或者在项目中存在对应的 `dev` 脚本。
- **配置：** 开发者可以根据项目需求自定义 `npm run dev` 命令的执行内容，在 `package.json` 中使用 `scripts` 字段来定义，例如：
#### 如何发布一个全局可执行命令的 npm package
在package.json中增加bin，对应脚本，脚本文件头部 #! usr/local/bin node之后npm link
#### 有没有用 npm 发布过 package，如何发布
注册 npm 账号 https://www.npmjs.com/
本地通过命令行 npm login 登陆
进入到项目目录下（与 package.json 同级），在 package.json 中指定发布文件、文件夹
{
"name": "pkg-xxx",
"version": "0.0.1",
"main": "lib/index.js",
"module": "esm/index.js",
"typings": "types/index.d.ts",
"files": [
"CHANGELOG.md",
"lib",
"esm",
"dist",
"types",
],
...
}
执行 npm publish --registry=https://registry.npmjs.org/ 即可发布
#### 如何对 npm package 进行发包
准备工作：一个账号,npm login,发布一个 npm 包之前，填写 package.json 中以下三项最重要的字段。假设此时包的名称为 @shanyue/just-demo
```
{
  name: '@shanyue/just-demo',
  version: '1.0.0',
  main: './index.js',
}
```
之后执行 npm publish 发包即可。
如若该包进行更新后，需要再次发包，可 npm version 控制该版本进行升级，记住需要遵守 Semver 规范
```
# 增加一个修复版本号: 1.0.1 -> 1.0.2 (自动更改 package.json 中的 version 字段)
$ npm version patch
# 增加一个小的版本号: 1.0.1 -> 1.1.0 (自动更改 package.json 中的 version 字段)
$ npm version minor
# 将更新后的包发布到 npm 中
$ npm publish
```
实际发包的内容
在 npm 发包时，实际发包内容为 package.json 中 files 字段，一般只需将构建后资源(如果需要构建)进行发包，源文件可发可不发。
```
{
  files: ["dist"];
}
```
若需要查看一个 package 的发包内容，可直接在 node_modules/${package} 进行查看，将会发现它和源码有很大不同。也可以在 CDN 中进行查看，以 React 为例
发包的实际流程
npm publish 将自动走过以下生命周期
prepublishOnly: 如果发包之前需要构建，可以放在这里执行
prepack
prepare: 如果发包之前需要构建，可以放在这里执行 (该周期也会在 npm i 后自动执行)
postpack
publish
postpublish
发包实际上是将本地 package 中的所有资源进行打包，并上传到 npm 的一个过程。你可以通过 npm pack 命令查看详情
#### 你有发布过自己的npm包吗？流程是怎样的？
首先需要注册一个npm账号：https://www.npmjs.com
在本地某个文件夹下使用命令：npm init 该命令其实就是用来引导你构建package.json文件的，文件夹名字应该就是你的包名
在该目录下新建你想要提交的文件，比如index.js等
写好readme.md,就像github的readme.js那样，描述你的包是干什么的，怎么用
通过npm login 指令输入你刚刚注册的账号和密码登录，登录成功后,可通过npm whoami 来查看登录信息
输入npm publish --access public 将你的包提交到npm平台上
静候佳音，如果一切顺利，过几分钟后就可以在npm上看到你发布的包了，你也可以通过npm搜索你的包，如果能搜索到，表示已经发布成功
注意：如果修改了包名，需要再次发布更新到线上时，一定要改变下版本号
#### 发布一个npm包如何忽略不需要发布的文件？
可以使用 .npmignore 文件、.gitignore文件和files字段来忽略不需要发布的文件
#### 如何加速 npm install
选择时延低的 registry，需要企业技术基础建设支持
NODE_ENV=production，只安装生产环境必要的包(如果 dep 与 devDep 没有仔细分割开来，工作量很大，可以放弃)
CI=true，npm 会在此环境变量下自动优化
结合 CI 的缓存功能，充分利用 npm cache
使用 npm ci 代替 npm i，既提升速度又保障应用安全性
#### npm i 与 npm ci 的区别是什么
npm ci (6.0 版本以上)
1。会删除项目中的 node_modules 文件夹；
2. 会依照项目中的package.json 来安装确切版本的依赖项；
3. 不像 npm install, npm ci 不会修改你的 package-lock.json 但是它确实期望你的项目中有一个 - package-lock.json 文件 - 如果你没有这个文件， npm ci 将不起作用，此时必须使用 npm install
#### npm i和npm install有什么区别？
npm i 和 npm install 的区别
实际使用的区别点主要如下(windows下)：
1. 用npm i安装的模块无法用npm uninstall删除，用npm uninstall i才卸载掉
2. npm i会帮助检测与当前node版本最匹配的npm包版本号，并匹配出来相互依赖的npm包应该提升的版本号
3. 部分npm包在当前node版本下无法使用，必须使用建议版本
4. 安装报错时install肯定会出现npm-debug.log 文件，npm i不一定
#### npm i 某个 package 时会修改 package-lock.json 中的版本号吗？
当 package-lock.json 该 package 锁死的版本号符合 package.json 中的版本号范围时，将以 package-lock.json 锁死版本号为主。
当 package-lock.json 该 package 锁死的版本号不符合 package.json 中的版本号范围时，将会安装该 package 符合 package.json 版本号范围的最新版本号，并重写 package-lock.json
#### npm workspaces 解决了什么问题
多个包难以互相链接
#### npm publish 时 npm script 的生命周期
prepublishOnly
prepack
prepare
postpack
publish
postpublish
#### 前端项目每次 npm install 之后需要执行一些处理工作，应该怎么办
使用 npm script 生命周期中的 npm prepare，他将会在发包 (publish) 之前以及装包 (install) 之后自动执行。
如果指向在装包之后自动执行，可使用 npm postinstall
```
{
    "prepare": "npm run build & node packages/husky/lib/bin.js install"
}
{
    "postinstall": "patch-package"
}
```
#### 简述 npm script 的生命周期
在 npm 中，使用 npm scripts 可以组织整个前端工程的工具链。
```
{
  start: 'serve ./dist',
  build: 'webpack',
  lint: 'eslint'
} 
```
   除了可自定义 npm script 外，npm 附带许多内置 scripts，他们无需带 npm run，可直接通过 npm `<script>` 执行
当我们执行任意 npm run 脚本时，将自动触发 pre/post 的生命周期。
当手动执行 npm run abc 时，将在此之前自动执行 npm run preabc，在此之后自动执行 npm run postabc。
```
// 自动执行
npm run preabc
npm run abc
// 自动执行
npm run postabc 
```
patch-package(opens new window) 一般会放到 postinstall 中。(patch-package对工程打补丁会对比当前与之前版本的diff生成patch文件)
```
{
  postinstall: "patch-package";
} 
```
而发包的生命周期更为复杂，当执行 npm publish，将自动执行以下脚本。
prepublishOnly: 最重要的一个生命周期。
prepack
prepare
postpack
publish
postpublish
当然你无需完全记住所有的生命周期，如果你需要在发包之前自动做一些事情，如测试、构建等，请在 prepulishOnly 中完成。
```
{
     prepublishOnly: "npm run test && npm run build";

} 
```
#### npm script一个最常用的生命周期
prepare
npm install 之后自动执行
npm publish 之前自动执行
```
{
  prepare: "husky install";
} 
```
npm script 钩子的风险
假设某一个第三方库的 npm postinstall 为 rm -rf /，那岂不是又很大的风险?
```
{
    postinstall: "rm -rf /";
}
```
实际上，确实有很多 npm package 被攻击后，就是通过 npm postinstall 自动执行一些事，比如挖矿等。
如果 npm 可以限制某些库的某些 hooks 执行，则可以解决这个问题。
#### npm提供了哪些钩子？各有什么作用？
npm 拥有以下的钩子命令：对于任何在 package.json 的 scripts 字段中定义的命令，可以通过 pre 以及 post 名称前缀，额外定义该任务在执行前、后的额外执行的钩子命令。例如：
```
{
    "scripts": {
        "premy-task": "echo 'task begin...'",
        "my-task": "node my-task.js",
        "postmy-task": "echo 'task completed!'"
    }
}
```
my-task 是某个目标命令名；在使用 npm 或 yarn 执行该命令（npm run my-task 或者是 yarn my-task）时，总是会自动的先去查找该命令是否有 pre 命令（即 premy-task），如果有就先执行该先决命令，且成功后再执行原命令 my-task；如果此命令成功结束了，总是会自动的去查找该任务是否有 post 命令（即 postmy-task），如果有就执行该后续命令。这种钩子命令，同样也能作用于一些 npm 客户端自身的行为，例如 install，uninstall 等。
#### npm是干什么用的？它有什么优缺点？有没有类似的方案？
一、npm 的优点包括：
1. 方便包管理：npm 提供了一个巨大包仓库，开发者可以方便地搜索、安装和更新各种开源包，避免了手动下载和管理依赖的麻烦。
2. 自动化依赖管理：npm 可以自动解析和管理项目中的依赖关系，根据 package.json 文件中的描述信息，安装所需的包和版本。
3. 社区支持和活跃度：npm 是一个非常活跃的社区，拥有大量的开发者和贡献者，可以获得广泛的支持和反馈。
4. 兼容性和跨平台性：npm 可以在不同的操作系统上运行，保证了代码包的跨平台性，并且与 Node.js 紧密集成，使用起来非常方便。
   二、然而，npm 也存在一些缺点：
1. 包版本管理：npm 的包版本管理机制有时候会导致依赖冲突和包更新问题，特别是当不同的包依赖于同一个包的不同版本时。
2. 依赖膨胀：由于 npm 的灵活性，很容易在项目中引入大量的依赖，这可能导致项目膨胀和性能下降。
3. 安全性：由于 npm 上的包是由社区开发者提供的，存在安全性的隐患，不小心引入恶意代码的风险也是需要注意的。
   三、类似于 npm 的包管理工具还有 yarn。yarn 是由 Facebook 开发的一个快速、可靠的包管理工具，它解决了 npm 的一些性能问题，并引入了一些新的功能，如离线安装、版本锁定等。
   总体而言，npm 是一个强大且广泛使用的包管理工具，可以方便地管理和共享 JavaScript 代码包。它的优点包括方便包管理、自动化依赖管理、活跃的社区支持和跨平台性。然而，也需要注意包版本管理、依赖膨胀和安全性等缺点。对于替代方案，yarn 是一个备选的包管理工具，可以提供更好的性能和一些额外的功能。"
#### 使用npm安装模块时，如何选择--save和--save-dev？
--save生产依赖--save-dev开发依赖
#### 在项目中，如何平滑升级 npm 包
npm 的版本号为 semver 规范，由 [major, minor, patch] 三部分组成，其中
major: 当你发了一个含有 Breaking Change 的 API
minor: 当你新增了一个向后兼容的功能时
patch: 当你修复了一个向后兼容的 Bug 时
可借助于 npm outdated，发现有待更新的 package
使用 npm outdated 虽能发现需要升级版本号的 package，但仍然需要手动在 package.json 更改版本号进行升级。
此时推荐一个功能更强大的工具 npm-check-updates，比 npm outdated 强大百倍。
npm-check-updates -u，可自动将 package.json 中待更新版本号进行重写
升级 [minor] 小版本号，有可能引起 Break Change，可仅仅升级到最新的 patch 版本。
npx npm-check-updates --target patch
当一个库的 major 版本号更新后，不要第一时间去更新，容易踩坑，可再度过几个 patch 版本号再更新尝试新功能
当遇到 major 版本号更新时，多看文档中的 ChangeLog，多看升级指导并多测试及审计
#### 简述 npm cache
npm 会把所有下载的包，保存在用户文件夹下面。
默认值：~/.npm在Posix上 或 %AppData%/npm-cache在Windows上。根缓存文件夹。
npm install 之后会计算每个包的 sha1 值(PS:安全散列算法(Secure Hash Algorithm))，然后将包与他的 sha1 值关联保存在 package-lock.json 里面，下次 npm install 时，会根据 package-lock.json 里面保存的 sha1 值去文件夹里面寻找包文件，如果找到就不用从新下载安装了。
npm cache verify 个命令是重新计算，磁盘文件是否与 sha1 值匹配，如果不匹配可能删除。
npm cache clean --force是删除磁盘所有缓存文件。
#### 如何修复某个 npm 包的紧急 bug
在 Github 提交 Pull Request，修复 Bug，等待合并
合并 PR 后，等待新版本发包
升级项目中的 lodash 依赖
patch-package
```
# 修改 lodash 的一个小问题
$ vim node_modules/lodash/index.js
# 对 lodash 的修复生成一个 patch 文件，位于 patches/lodash+4.17.21.patch
$ npx patch-package lodash
# 将修复文件提交到版本管理之中
$ git add patches/lodash+4.17.21.patch
$ git commit -m "fix 一点儿小事 in lodash"
# 此后的命令在生产环境或 CI 中执行
# 此后的命令在生产环境或 CI 中执行
# 此后的命令在生产环境或 CI 中执行
# 在生产环境装包
$ npm i
# 为生产环境的 lodash 进行小修复
$ npx patch-package
# 大功告成！
```
patch-package 自动生成 patch 文件
它实际上是一个 diff 文件，在生产环境中可自动根据 diff 文件与版本号 (根据patch文件名存取) 将修复场景复原
```
$ cat patches/lodash+4.17.21.patch
diff --git a/node_modules/lodash/index.js b/node_modules/lodash/index.js
index 5d063e2..fc6fa33 100644
--- a/node_modules/lodash/index.js
+++ b/node_modules/lodash/index.js
@@ -1 +1,3 @@
+console.log('DEBUG SOMETHING')
+
 module.exports = require('./lodash');
\ No newline at end of file
```
#### .npmrc配置文件有什么用途？
.npmrc 文件的主要作用是定义npm的配置选项。 这些配置选项可以控制npm在安装、发布、更新和管理包时的行为。
它允许开发者根据项目的需求来自定义npm的行为，以便更有效地管理依赖关系、提高安全性，或者加速包的下载速度。
#### 如何查看 node_modules(某一文件夹) 的体积有多大
du -hd 1 node_modules
#### 请描述 node_modules 的目录结构(拓扑结构)
当 require('package-hello') 时，假设 package-hello 是一个 npm 库，我们是如何找到该 package 的？
寻找当前目录的 node_modules/package-hello 目录
如果未找到，寻找上一级的 ../node_modules/package-hello 目录，以此递归查找
很久以前: 嵌套结构,现在阶段: 平铺结构
#### 什么是 semver，~1.2.3 与 ^1.2.3 的版本号范围是多少
对于 ~1.2.3 而言，它的版本号范围是 >=1.2.3 <1.3.0
对于 ^1.2.3 而言，它的版本号范围是 >=1.2.3 <2.0.0
#### semver 指什么，试图解释一下
语义化版本号。版本格式：主版本号.次版本号.修订号
#### 如何为一个项目指定 node 版本号
指定一个项目所需的 node 最小版本，这属于一个项目的质量工程。
如果对于版本不匹配将会报错(yarn)或警告(npm)，那我们需要在 package.json 中的 engines 字段中指定 Node 版本号
{
"engines": {
"node": ">=14.0.0"
}
}
#### 说说你对package.json的理解，它都有哪些作用？
package.json 是 Node.js 开发中使用的重要元数据文件。 它有助于管理依赖关系、自动化任务、并配置项目。
该文件包含了项目名称、版本号、作者、许可证、依赖关系等基本信息。
通过使用 package.json ，我们可以轻松管理项目所需的依赖项，确保安装每个软件包的正确版本
#### package.json 中 main/module/browser/exports 字段有何区别
1. main
   main 指 npm package 的入口文件，当我们对某个 package 进行导入时，实际上导入的是 main 字段所指向的文件。main 是 CommonJS 时代的产物，也是最古老且最常用的入口文件。
```
// package.json 内容
{
  name: 'midash',
  main: './dist/index.js'
}
// 关于如何引用 package
const midash = require('midash')
// 实际上是通过 main 字段来找到入口文件，等同于该引用
const midash = require('midash/dist/index.js') 
```
2. module
   随着 ESM 且打包工具的发展，许多 package 会打包 N 份模块化格式进行分发，如 antd 既支持 ES，也支持 umd，将会打包两份。
   如果使用 import 对该库进行导入，则首次寻找 module 字段引入，否则引入 main 字段。 基于此，许多前端友好的库，都进行了以下分发操作:对代码进行两份格式打包: commonjs 与 es module
   module 字段作为 es module 入口
   main 字段作为 commonjs 入口
```
{
   name: 'midash',
   main: './dist/index.js',
   module: './dist/index.mjs'
}
// 以下两者等同
import midash from 'midash'
import midash from 'midash/dist/index.mjs'
```
如果你的代码只分发一份 es module 模块化方案，则直接置于 main 字段之中。
3. exports
   如果说以上两个是刀剑，那 exports 至少得是瑞士军刀。exports 可以更容易地控制子目录的访问路径，也被称为 export map。
   不在 exports 字段中的模块，即使直接访问路径，也无法引用！
```
// package.json
{
  name: 'midash',
  main: './index.js',
  exports: {
    '.': './dist/index.js',
    'get': './dist/get.js'
  }
}
// 正常工作
import get from 'midash/get'
// 无法正常工作，无法引入
import get from 'midash/dist/get' 
```
exports 不仅可根据模块化方案不同选择不同的入口文件，还可以根据环境变量(NODE_ENV)、运行环境(nodejs/browser/electron) 导入不同的入口文件。
```
{
  "type": "module",
  "exports": {
    "electron": {
      "node": {
        "development": {
          "module": "./index-electron-node-with-devtools.js",
          "import": "./wrapper-electron-node-with-devtools.js",
          "require": "./index-electron-node-with-devtools.cjs"
        },
        "production": {
          "module": "./index-electron-node-optimized.js",
          "import": "./wrapper-electron-node-optimized.js",
          "require": "./index-electron-node-optimized.cjs"
        },
        "default": "./wrapper-electron-node-process-env.cjs"
      },
      "development": "./index-electron-with-devtools.js",
      "production": "./index-electron-optimized.js",
      "default": "./index-electron-optimized.js"
    },
    "node": {
      "development": {
        "module": "./index-node-with-devtools.js",
        "import": "./wrapper-node-with-devtools.js",
        "require": "./index-node-with-devtools.cjs"
      },
      "production": {
        "module": "./index-node-optimized.js",
        "import": "./wrapper-node-optimized.js",
        "require": "./index-node-optimized.cjs"
      },
      "default": "./wrapper-node-process-env.cjs"
    },
    "development": "./index-with-devtools.js",
    "production": "./index-optimized.js",
    "default": "./index-optimized.js"
  }
} 
```
#### package-lock.json 有什么作用，如果项目中没有它会怎么样，举例说明
正常情况下如果按照semver规范是没有问题的
演示风险过程如下:
pkg 1.2.3: 首次在开发环境安装 pkg 库，为此时最新版本 1.2.3，dependencies 依赖中显示 ^1.2.3，实际安装版本为 1.2.3
pkg 1.19.0: 在生产环境中上线项目，安装 pkg 库，此时最新版本为 1.19.0，满足 dependencies 中依赖 ^1.2.3 范围，实际安装版本为 1.19.0，但是 pkg 未遵从 semver 规范，在此过程中引入了 Breaking Change，如何此时 1.19.0 有问题的话，那生产环境中的 1.19.0 将会导致 bug，且难以调试
而当有了 lock 文件时，每一个依赖的版本号都被锁死在了 lock 文件，每次依赖安装的版本号都从 lock 文件中进行获取，避免了不可测的依赖风险。
pkg 1.2.3: 首次在开发环境安装 pkg 库，为此时最新版本 1.2.3，dependencies 依赖中显示 ^1.2.3，实际安装版本为 1.2.3，在 lock 中被锁定版本号
pkg 1.2.3: 在生产环境中上线项目，安装 pkg 库，此时 lock 文件中版本号为 1.2.3，符合 dependencies 中 ^1.2.3 的范围，将在生产环境安装 1.2.3，完美上线。
#### package-lock.json 与 yarn.lock 有什么区别
package-lock.json把所有的包的依赖顺序列出来，第一次出现的包名会提升到顶层，后面重复出现的将会放入被依赖包的node_modules当中。引起不完全扁平化问题。
yarn.lock锁文件把所有的依赖包都扁平化的展示了出来，对于同名包但是semver不兼容的作为不同的字段放在了yarn.lock的同一级结构中。
#### peerDependency 是为了解决什么问题
避免重复安装
#### optionalDependencies 的使用场景是什么
当一个包是可依赖可不依赖时，可采用 optionalDependencies，但需要在代码中做好异常处理。
#### dependencies 与 devDependencies 有何区别
dependencies字段指定了项目运行所依赖的模块，devDependencies指定项目开发所需要的模块。
当你在软件包目录下执行npm install命令时，dependencies、devDependencies指定的三方软件包均会在node_modules目录下安装，若执行npm install --production命令，则不会安装devDependencies指定的三方软件包。但当软件包作为三方软件包被安装时（npm install $package）,则dependencies指定的软件包会被安装，devDependencies指定指定的软件包不会被安装。
了解dependencies和devDependencies的作用后，我们在开发软件包时，哪些依赖应该放入dependencies，哪些依赖应该放入devDependencies中。
首先我们要明确放入dependencies中的依赖软件包，是我们的项目在生产环境下运行时必须依赖的软件包，其的部分功能或全部功能通常会被打包到我们工程发布的bundles中。而放入devDependencies中软件包是我们的工程在开发时依赖的软件包，通常情况下以下的依赖会被放入devDependencies中：
格式化代码或错误检查类软件包：esLint、prettier
打包工具及其插件：webpack, gulp, parceljs
babel及其的插件
单元测试类：enzyme, jest
#### yarn和npm有什么区别？
速度快 。速度快主要来自以下两个方面：
并行安装：无论 npm 还是 Yarn 在执行包的安装时，都会执行一系列任务。npm 是按照队列执行每个 package，也就是说必须要等到当前 package 安装完成之后，才能继续后面的安装。而 Yarn 是同步执行所有任务，提高了性能。
离线模式：如果之前已经安装过一个软件包，用Yarn再次安装时之间从缓存中获取，就不用像npm那样再从网络下载了。
安装版本统一：为了防止拉取到不同的版本，Yarn 有一个锁定文件 (lock file) 记录了被确切安装上的模块的版本号。每次只要新增了一个模块，Yarn 就会创建（或更新）yarn.lock 这个文件。这么做就保证了，每一次拉取同一个项目依赖时，使用的都是一样的模块版本。npm 其实也有办法实现处处使用相同版本的 packages，但需要开发者执行 npm shrinkwrap 命令。这个命令将会生成一个锁定文件，在执行 npm install 的时候，该锁定文件会先被读取，和 Yarn 读取 yarn.lock 文件一个道理。npm 和 Yarn 两者的不同之处在于，Yarn 默认会生成这样的锁定文件，而 npm 要通过 shrinkwrap 命令生成 npm-shrinkwrap.json 文件，只有当这个文件存在的时候，packages 版本信息才会被记录和更新。
更简洁输出：npm 的输出信息比较冗长。在执行 npm install 的时候，命令行里会不断地打印出所有被安装上的依赖。相比之下，Yarn 简洁太多：默认情况下，结合了 emoji直观且直接地打印出必要的信息，也提供了一些命令供开发者查询额外的安装信息。
多注册来源处理：所有的依赖包，不管他被不同的库间接关联引用多少次，安装这个包时，只会从一个注册来源去装，要么是 npm 要么是 bower, 防止出现混乱不一致。
更好的语义化： yarn改变了一些npm命令的名称，比如 yarn add/remove，感觉上比 npm 原本的 install/uninstall 要更清晰。
#### yarn模块中的yarn.lock文件有什么作用？
使用确定性算法，在将文件放置到需要的位置之前构建整个依赖关系树。安装过程中重要信息存储到yarn.lock文件中，以便可以在安装依赖关系的每个系统之间共享！此文件包含有关已安装的每个依赖项的确切版本的信息以及代码的校验和以确保代码完全相同。
此文件会锁定你安装的每个依赖项的版本，这可以确保你不会意外获得不良依赖；并且会避免由于开发人员意外更改或更新版本，而导致糟糕的情况
#### npm 第三方库需要提交 lockfile 吗
你自己项目中所有依赖都会根据 lockfile 被锁死，但并不会依照你第三方依赖的 lockfile。
lockfile 对于第三方库仍然必不可少。可见 react、next.js、webpack 均有 yarn.lock。(PS: 可见 yarn 的受欢迎程度，另外 vue3 采用了 pnpm)
第三方库的 devDependencies 必须在 lockfile 中锁定，这样 Contributor 可根据 lockfile 很容易将项目跑起来。
第三方库的 dependencies 虽然有可能存在不可控问题，但是可通过锁死 package.json 依赖或者勤加更新的方式来解决。
#### 你有使用过npx吗？它主要解决什么问题？
1. 在命令行下,调用内部安装模块
2. 避免全局安装模块
#### 前端打包时 cjs、es、umd 模块有何不同
1. cjs (commonjs)commonjs 是 Node 中的模块规范，通过 require 及 exports 进行导入导出 (进一步延伸的话，module.exports 属于 commonjs2)
   同时，webpack 也对 cjs 模块得以解析，因此 cjs 模块可以运行在 node 环境及 webpack 环境下的，但不能在浏览器中直接使用。但如果你写前端项目在 webpack 中，也可以理解为它在浏览器和 Node 都支持
   cjs 为动态加载，可直接 require 一个变量
2. esm (es module) esm 是 tc39 对于 ESMAScript 的模块话规范，正因是语言层规范，因此在 Node 及 浏览器中均会支持。 它使用 import/export 进行模块导入导出.
   esm 为静态导入，正因如此，可在编译期进行 Tree Shaking，减少 js 体积。
- cjs与esm对比
  cjs 模块输出的是一个值的拷贝，esm 输出的是值的引用
  cjs 模块是运行时加载，esm 是编译时加载
3. umd  一种兼容 cjs 与 amd 的模块，既可以在 node/webpack 环境中被 require 引用，也可以在浏览器中直接用 CDN 被 script.src 引入。
   这三种模块方案大致如此，部分 npm package 也会同时打包出 commonjs/esm/umd 三种模块化格式，供不同需求的业务使用
#### require和import有什么区别？
require 是动态的，可以在运行时根据需要加载模块，而 import 是静态的，必须在编译时就确定要加载哪些模块。 
require 返回的是一个对象，需要通过对象属性来访问模块中的方法和变量，而 import 可以直接导入模块中的方法和变量
#### 浏览器中如何使用原生的 ESM
通过 script[type=module]，可直接在浏览器中使用原生 ESM。这也使得前端不打包 (Bundless) 成为可能。
```
<script type="module">
  import lodash from "https://cdn.skypack.dev/lodash";
</script>
```
由于前端跑在浏览器中，因此它也只能从 URL 中引入 Package
1. 绝对路径: https://cdn.sykpack.dev/lodash
2. 相对路径: ./lib.js
   现在打开浏览器控制台，把以下代码粘贴在控制台中。由于 http import 的引入，你发现你调试 lodash 此列工具库更加方便了。
```
> lodash = await import('https://cdn.skypack.dev/lodash')
> lodash.get({ a: 3 }, 'a')
```  
在 ESM 中，可通过 importmap 使得裸导入可正常工作:
```
<script type="importmap">
  {
    "imports": {
      "lodash": "https://cdn.skypack.dev/lodash",
      "lodash/": "https://cdn.skypack.dev/lodash/"
    }
  }
</script>
<script type="module">
  import get from "lodash/get.js";
</script>
```
通过 script[type=module]，不仅可引入 Javascript 资源，甚至可以引入 JSON/CSS，示例如下
```
<script type="module">
  import data from "./data.json" assert { type: "json" };
 
  console.log(data);
</script>
```
三点注意
1.module默认是defer的加载和执行方式
2.这里会存在单独的module的域不会污染到全局
3.直接是strict
#### 如何将 CommonJS 转化为 ESM
CommonJS 向 ESM 转化，自然有构建工具的参与，比如
@rollup/plugin-commonjs
甚至把一些 CommonJS 库转化为 ESM，并且置于 CDN 中，使得我们可以直接使用，而无需构建工具参与
https://cdn.skypack.dev/
https://jspm.org/

#### 当新入职一家公司时，如何快速搭建开发环境并让应用跑起来
查看是否有 CI/CD，如果有跟着 CI/CD 部署的脚本跑命令
查看是否有 dockerfile，如果有跟着 dockerfile 跑命令
查看 npm scripts 中是否有 dev/start，尝试 npm run dev/npm start
查看是否有文档，如果有跟着文档走。为啥要把文档放到最后一个？原因你懂的
但即便是十分谨慎，也有可能遇到以下几个叫苦不迭、浪费了一下午时间的坑:
前端有可能在本地环境启动时需要依赖前端构建时所产生的文件，所以有时需要先正常部署一遍，再试着按照本地环境启动 (即需要先 npm run build 一下，再 npm run dev/npm start)。(比如，一次我们的项目 npm run dev 时需要 webpack DllPlugin 构建后的东西）
别忘了设置环境变量或者配置文件 (.env/consul/k8s-configmap)
因此，设置一个少的 script，可以很好地避免后人踩坑，更重要的是，可以避免后人骂你，
此时可设置 script hooks，如 prepare、postinstall 自动执行脚本，来完善该项目的基础设施
{
"scripts": {
"start": "npm run dev",
"config": "node assets && node config",
"build": "webpack",
// 设置一个钩子，在 npm install 后自动执行，此处有可能不是必须的
"prepare": "npm run build",
"dev": "webpack-dev-server --inline --progress"
}
}
#### 什么是前端工程化
前端工程化的主要目标就是解放生产力、提高生产效率。通过制定一系列的规范，借助工具和框架解决前端开发以及前后端协作过程中的痛点和难度问题。
#### 你们的前端代码上线部署一次需要多长时间，需要人为干预吗
更短的部署时间，更少的人为干预，更有利于敏捷开发
#### 刚刚启动了一个服务，如何知道这个服务对应的端口号是多少
在 linux 系统中，我通常通过 ps -aux |grep 服务名
#### 简述 browserslist 的意义
browserslist 是在不同的前端工具之间共用目标浏览器和 node 版本的配置工具。 相当于给 Babel、PostCSS、ESLint、StyleLint 等这些前端工具预设一个浏览器支持范围，这些工具转换或检查代码时会参考这个范围。
谈一下 browserslist 的原理: browserslist 根据正则解析查询语句，对浏览器版本数据库 caniuse-lite 进行查询，返回所得的浏览器版本列表。
caniuse-lite 这个库也由 browserslist 团队进行维护，它是基于 caniuse 的数据库进行的数据整合。
npx browserslist@latest --update-db
一些常用的查询语法
根据用户份额:
```
> 5%: 在全球用户份额大于 5% 的浏览器
> 5% in CN: 在中国用户份额大于 5% 的浏览器
```
根据最新浏览器版本:
```
last 2 versions: 所有浏览器的最新两个版本
last 2 Chrome versions: Chrome 浏览器的最新两个版本
```
不再维护的浏览器
```
dead: 官方不在维护已过两年，比如 IE10
```
浏览器版本号
```
Chrome > 90: Chrome 大于 90 版本号的浏览器
```
#### 如何确认你们项目是否依赖某一个依赖项
npm list
#### 当你引入某一个依赖项时，你引入的是该依赖下的哪一个文件
目前 main、module、exports 是用的最多的几项字段，browser 目前用的越来越少了
#### npm 执行命令传递参数时，为何需要双横线
npm脚本执行时会开启一个shell，执行后面指定的脚本命令或文件， -- 是为了给后面shell脚本命令传递参数，类似node环境的process.argv的吧。
#### 如何压缩前端项目中 JS 的体积
1. terser(opens new window) 或者 uglify(opens new window)，及流行的使用 Rust 编写的 swc 压缩混淆化 JS。
2. gzip 或者 brotli 压缩，在网关处(nginx)开启
3. 使用 webpack-bundle-analyzer 分析打包体积，替换占用较大体积的库，如 moment -> dayjs
4. 使用支持 Tree-Shaking 的库，对无引用的库或函数进行删除，如 lodash -> lodash/es
5. 对无法 Tree Shaking 的库，进行按需引入模块，如使用 import Button from 'antd/lib/Button'，此处可手写 babel-plugin 自动完成，但不推荐
6. 使用 babel (css 为 postcss) 时采用 browserlist，越先进的浏览器所需要的 polyfill 越少，体积更小
7. code split，路由懒加载，只加载当前路由的包，按需加载其余的 chunk，首页 JS 体积变小 (PS: 次条不减小总体积，但减小首页体积)
8. 使用 webpack 的 splitChunksPlugin，把运行时、被引用多次的库进行分包，在分包时要注意避免某一个库被多次引用多次打包。此时分为多个 chunk，虽不能把总体积变小，但可提高加载性能 (PS: 此条不减小总体积，但可提升加载性能)
   压缩的具体操作
1. 去除多余字符，eg：空格，换行、注释
2. 压缩变量名，函数名、属性名
3. 使用更简单的表达，eg：合并声明、布尔值简化
#### 你们项目中使用了哪些依赖/第三方库
lodash axios echarts file-saver patch-package qs sortablejs vue-clipboard2 xlsx watermark-dom
#### 如何查看你们 JS 项目中应采用的 node 版本
packageJson.engines，第三方模块都会有，自己的项目中有可能有
pm2.app[].interpreter，如果采用 pm2 部署，可以查看 interpreter 选项，但不保证该项存在
FROM，如果采用 docker 部署，查看基础镜像 Dockerfile 中 node 的版本号
如果以上方式都不可以，那只有问人了
#### 同一页面三个组件请求同一个 API 发送了三次请求，如何优化
```js
const fetchUser = (id) => {
  return new Promise((resolve) => {
    setTimeout(() => {
      console.log("Fetch: ", id);
      resolve(id);
    }, 5000);
  });
};
const cache = {};
const cacheFetchUser = (id) => {
  if (cache[id]) {
    return cache[id];
  }
  cache[id] = fetchUser(id);
  return cache[id];
};
cacheFetchUser(3).then((id) => console.log(id))
cacheFetchUser(3).then((id) => console.log(id))
cacheFetchUser(3).then((id) => console.log(id))
// Fetch:  3
// 3
// 3
// 3 
```
#### 你会搭建私有的npm仓库吗？怎么搭建？
verdaccio工具搭建
1. npm install -g verdaccio
2. 配置文件修改在verdaccio目录找到配置文件修改相关配置比如域名端口
3. verdaccio启动也可以使用pm2启动 pm2 start verdaccio,重启pm2 restart verdaccio 停止pm2 stop verdaccio
4. 发布流程只需按照npm修改配置好的源地址即可
#### performance API 中什么指标可以衡量首屏时间
// 首屏时间
timingInfo.domComplete - timingInfo.fetchStart;
#### 如何提高首屏渲染时间？
1. 对于 pv 量比较高的页面，比如 b 站等流量图也比较大的，采用 ssr 采用 ssr 如何优化性能
   性能瓶颈在于 react-dom render/hydrate 和 server 端的 renderToString
   尽量减少 dom 结构， 采用流式渲染，jsonString 一个对象，而不是 literal 对象
   server 去获取数据
   不同情况不同分析，减少主线程阻塞时间
   减少不必要的应用逻辑在服务端运行
2. 减少依赖和包的体积
   利用 webpack 的 contenthash 缓存
   重复依赖包处理，可以采用 pnpm
   采用 code splitting，减少首次请求体积
   减少第三方依赖的体积
3. FP (First Paint) 首次绘制 FCP (First Contentful Paint) 首次内容绘制 LCP (Largest Contentful Paint) 最大内容渲染 DCL (DomContentloaded) FMP(First Meaningful Paint) 首次有效绘制 L (onLoad) TTI (Time to Interactive) 可交互时间 TBT (Total Blocking Time) 页面阻塞总时长 FID (First Input Delay) 首次输入延迟 CLS (Cumulative Layout Shift) 累积布局偏移 SI (Speed Index) 一些性能指标可以监控性能
4. 网络 prefetch cdn
#### 什么是 Open Graph 协议，用来做什么
Open Graph 协议可以让任何一个网页集成到社交图谱中。例如，facebook 就是一种社交图谱(social graph)。 一旦一个网页按照该协议进行集成，这个网页就像是社交图谱的一个节点，例如，你的网页集成了 open graph 协议， 按照协议加入了网页的标题，描述以及图片信息等等，那么你在 facebook 中分享这个网页的时候，facebook 就会按照 你定义的内容来展示这个网页。
这个协议其实很简单，主要是通过在 html 中加入一些元数据（meta）标签来实现，例如 在 head 中加入 meta 标签，property 是以 og(open graph)开头, 后面跟着具体属性，content 里面是属性的值， 下面这段描述的就是一个类型为 video.movie，标题为 The rock，以及 url 和图片信息。这个例子就可以当做是 为 https://www.imdb.com/title/tt0117500/ 实现了 Open Graph 协议、
```
<html prefix="og: http://ogp.me/ns#">
<head>
<title>The Rock (1996)</title>
<meta property="og:title" content="The Rock" />
<meta property="og:type" content="video.movie" />
<meta property="og:url" content="http://www.imdb.com/title/tt0117500/" />
<meta property="og:image" content="http://ia.media-imdb.cimg/rock.jpg" />
...
</head>
...
</html> 
```
结论： 这个协议主要是 Facebook 提出来的，为了更好展示用户分享的网页的内容，实现这个协议，有助于 SEO 优化，告诉 google 该网页有哪些内容，以及关键词等。
#### 你是如何保障你们项目质量的
lint
type
test
code review
git hooks
CI
#### 什么是服务器渲染 (SSR)
服务器渲染 (SSR)：将同一个组件渲染为服务器端的 HTML 字符串，将它们直接发送到浏览器，最后将这些静态标记"激活"为客户端上完全可交互的应用程序。这个过程可以成为服务端渲染。
优势： 更好的 SEO 更快的内容到达时间 (time-to-content)
#### js 代码压缩 minify 的原理是什么
通过 AST 分析，根据选项配置一些策略，来生成一颗更小体积的 AST 并生成代码。
目前前端工程化中使用 terser(opens new window) 和 swc(opens new window) 进行 JS 代码压缩，他们拥有相同的 API。
常见用以压缩 AST 的几种方案如下:
去除多余字符: 空格，换行及注释
// 对两个数求和
function sum (a, b) {
return a + b;
}
此时文件大小是 62 Byte， 一般来说中文会占用更大的空间。
多余的空白字符会占用大量的体积，如空格，换行符，另外注释也会占用文件体积。当我们把所有的空白符合注释都去掉之后，代码体积会得到减少。
去掉多余字符之后，文件大小已经变为 30 Byte。 压缩后代码如下:
function sum(a,b){return a+b}
替换掉多余字符后会有什么问题产生呢？
有，比如多行代码压缩到一行时要注意行尾分号。
压缩变量名：变量名，函数名及属性名
function sum (first, second) {
return first + second;  
}
如以上 first 与 second 在函数的作用域中，在作用域外不会引用它，此时可以让它们的变量名称更短。但是如果这是一个 module 中，sum 这个函数也不会被导出呢？那可以把这个函数名也缩短。
// 压缩: 缩短变量名
function sum (x, y) {
return x + y;  
}
// 再压缩: 去除空余字符
function s(x,y){return x+y}
在这个示例中，当完成代码压缩 (compress) 时，代码的混淆 (mangle) 也捎带完成。 但此时缩短变量的命名也需要 AST 支持，不至于在作用域中造成命名冲突。
解析程序逻辑：合并声明以及布尔值简化
通过分析代码逻辑，可对代码改写为更精简的形式。
合并声明的示例如下：
// 压缩前
const a = 3;
const b = 4;
// 压缩后
const a = 3, b = 4;
布尔值简化的示例如下：
// 压缩前
!b && !c && !d && !e
// 压缩后
!(b||c||d||e)
解析程序逻辑: 编译预计算
在编译期进行计算，减少运行时的计算量，如下示例:
// 压缩前
const ONE_YEAR = 365 * 24 * 60 * 60
// 压缩后
const ONE_YAAR = 31536000
以及一个更复杂的例子，简直是杀手锏级别的优化。
// 压缩前
function hello () {
console.log('hello, world')
}
hello()
// 压缩后
console.log('hello, world')
#### 图片防盗链原理是什么
请求头中的 refer 来判断是否屏蔽图片
#### 什么是浏览器的关键渲染路径
01 DOM
生成 DOM 会从远程下载 Byte，并根据相应的编码 (如 utf8) 转化为字符串，通过 AST 解析为 Token，生成 Node 及最后的 DOM。
02 CSSOM
当解析 CSS 文件时，最终会生成 CSSOM
03 Render Tree
DOM 与 CSSOM 会一起生成 Render Tree，只包含渲染网页所需的节点。
04 Layout
计算每一个元素在设备视口内的确切位置和大小
05 Paint
将渲染树中的每个节点转换成屏幕上的实际像素，这一步通常称为绘制或栅格化
#### 你使用过哪些前端性能分析工具
lighthouse: 可在 chrome devtools 直接使用，根据个人设备及网络对目标网站进行分析，并提供各种建议
web page test: 分布式的性能分析工具，可在全球多个区域的服务器资源为你的网站进行分析，并生成相应的报告
#### 在 nginx 中如何配置负载均衡
通过 proxy_pass 与 upstream 即可实现最为简单的负载均衡。如下配置会对流量均匀地导向 172.168.0.1，172.168.0.2 与 172.168.0.3 三个服务器
```
http {
  upstream backend {
      server 172.168.0.1;
      server 172.168.0.2;
      server 172.168.0.3;
  }
  server {
      listen 80;
      location / {
          proxy_pass http://backend;
      }
  }
} 
```
关于负载均衡的策略大致有以下四种种
round_robin: 轮询，nginx 默认的负载均衡策略就是轮询，假设负载三台服务器节点为 A、B、C，则每次流量的负载结果为 ABCABC
weighted_round_robin: 加权轮询，根据关键字 weight 配置权重，如下则平均没来四次请求，会有八次打在 A，会有一次打在 B，一次打在 C
ip_hash: 对每次的 IP 地址进行 Hash，进而选择合适的节点，如此，每次用户的流量请求将会打在固定的服务器上，利于缓存，也更利于 AB 测试等。
least_conn: 选择连接数最少的服务器节点优先负载
#### 简述 bundless 的优势与不足
Bundleless 的优势。
1.项目启动快。因为不需要过多的打包，只需要处理修改后的单个文件，所以响应速度是 O(1) 级别，刷新即可即时生效，速度很快。
2.浏览器加载块。利用浏览器自主加载的特性，跳过打包的过程。
3.本地文件更新，重新请求单个文件。
|             | bundle      | bundleless |
| ----------- | ----------- | ----------- |
| 项目启动      | 完整打包项目  | 启动devServer |
| 浏览器加载   | 等到打包完成，加载对应的bundle | 直接发送请求，映射道本地文件|
| 本地文件更新   | 重新打包bundle | 重新请求单个文件 |
#### 简述你们前端项目中资源的缓存配置策略
非工程化项目
|  \             |  html                         | css和js               |	图片    |
|  ------------  |  ---------------------------- | -------------------- |--------  |
| 频率            | 可能会频繁更改，需要每次都询问。    | 可能每月修改           | 几乎不变   |
| Cache-Control  | private, no-cache             | Public, max-age=2592000 (一个月) | Public, max-age=31536000 (一年)，stale-while-revalidate=86400 |
| 使缓存失效       | 每次都要询问，确保最新            | 自动过期或改名字（hash值）        | 自动过期或改名字（hash值） |

现代工程化架构下的最佳缓存策略有所不同
|  \             |  html                         | css和js               |	图片    |
|  ------------  |  ---------------------------- | -------------------- |--------  |
| 频率            | 可能会频繁更改，需要每次都询问。    | 可能每月修改           | 几乎不变   |
| Cache-Control  | private, no-cache             | Public, max-age=31536000 (一年甚至永久) | Public, max-age=31536000 (一年甚至永久)，stale-while-revalidate=86400 |
| 使缓存失效       | 每次都要询问，确保最新            | 改名字（hash值）        |改名字（hash值） |
#### 现代前端应用应如何配置 HTTP 缓存机制
文件路径中带有 hash 值：一年的强缓存。因为该文件的内容发生变化时，会生成一个带有新的 hash 值的 URL。前端将会发起一个新的 URL 的请求。配置响应头 Cache-Control: public,max-age=31536000,immutable
文件路径中不带有 hash 值：协商缓存。大部分为 public 下文件。配置响应头 Cache-Control: no-cache 与 etag/last-modified
但是当处理永久缓存时，切记不可打包为一个大的 bundle.js，此时一行业务代码的改变，将导致整个项目的永久缓存失效，此时需要按代码更新频率分为多个 chunk 进行打包，可细粒度控制缓存。
webpack-runtime: 应用中的 webpack 的版本比较稳定，分离出来，保证长久的永久缓存
react/react-dom: react 的版本更新频次也较低
vendor: 常用的第三方模块打包在一起，如 lodash，classnames 基本上每个页面都会引用到，但是它们的更新频率会更高一些。另外对低频次使用的第三方模块不要打进来
pageA: A 页面，当 A 页面的组件发生变更后，它的缓存将会失效
pageB: B 页面
echarts: 不常用且过大的第三方模块单独打包
mathjax: 不常用且过大的第三方模块单独打包
jspdf: 不常用且过大的第三方模块单独打包
#### 引入 BFF 层的优势在哪里
BFF 全称 Backend For Frontend，一般指在前端与服务器端搭建一层由前端维护的 Node Server 服务，具有以下好处
数据处理。对数据进行校验、清洗及格式化。使得数据更与前端契合
数据聚合。后端无需处理大量的表连接工作，第三方接口聚合工作，业务逻辑简化为各个资源的增删改查，由 BFF 层聚合各个资源的数据，后端可集中处理性能问题、监控问题、消息队列等
权限前移。在 BFF 层统一认证鉴权，后端无需做权限校验，后端可直接部署在集群内网，无需向外网暴露服务，减少了后端的服务度。
但其中也有一些坏处，如以下
引入复杂度，新的 BFF 服务需要一套基础设施的支持，如日志、异常、部署、监控等
#### 如何处理白屏错误页的监控的？
排查兼容性。大部分原因低端机型/浏览器低版本 polyfill 的问题导致报错
排查网络。js 是否下载成功 cdn 是否生效
做 js 错误上报。分析是否存在代码缺陷
做重试逻辑/诱导用户重试
Error Boundary 避免整页崩溃。限制在组件级别
#### 如何检测出你们安装的依赖是否安全
1. Audit，审计，检测你的所有依赖是否安全。npm audit/yarn audit 均有效
   通过审计，可看出有风险的 package、依赖库的依赖链、风险原因及其解决方案。
   通过 npm audit fix 可以自动修复该库的风险，原理就是升级依赖库，升级至已修复了风险的版本号。
   yarn audit 无法自动修复，需要使用 yarn upgrade 手动更新版本号，不够智能。
   synk 是一个高级版的 npm audit，可自动修复，且支持 CICD 集成与多种语言。
   $ npx snyk
   $ npx wizard
2. 可通过 CI/gitlab/github 中配置机器人，使他们每天轮询一次检查仓库的依赖中是否有风险。
   在 Github 中，可单独设置 dependabot 机器人，在仓库设置中开启小机器人，当它检测到有问题时，会自动向该仓库提交 PR。
   而它的解决方案也是升级版本号。
#### 什么是安全的正则表达式
```
const safe = require("safe-regex");
const re = /(x+x+)+y/;
// 能跑死 CPU 的一个正则
re.test("xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx");
// 使用 safe-regex 判断正则是否安全
safe(re); // false
```
#### pnpm 有什么优势
通过 ln -s 创建一个软链接，通过 ln 可以创建一个硬链接。
软链接可理解为指向源文件的指针，它是单独的一个文件，仅仅只有几个字节，它拥有独立的 inode
硬链接与源文件同时指向一个物理地址，它与源文件共享存储数据，它俩拥有相同的 inode
pnpm 为何节省空间
它解决了 npm/yarn 平铺 node_modules 带来的依赖项重复的问题 (doppelgangers)
假设存在依赖依赖:
```
├── package-a
│   └── lodash@4.0.0
├── package-b
│   └── lodash@4.0.0
├── package-c
│   └── lodash@3.0.0
└── package-d
    └── lodash@3.0.0
```
那么不可避免地在 npm 或者 yarn 中，lodash@3.0.0 会被多次安装，无疑造成了空间的浪费与诸多问题。
而在 pnpm 中，它改变了 npm/yarn 的目录结构，采用软链接的方式，避免了问题更加节省空间
```
./node_modules/package-a       ->  .pnpm/package-a@1.0.0/node_modules/package-a
./node_modules/package-b       ->  .pnpm/package-b@1.0.0/node_modules/package-b
./node_modules/package-c       ->  .pnpm/package-c@1.0.0/node_modules/package-c
./node_modules/package-d       ->  .pnpm/package-d@1.0.0/node_modules/package-d
./node_modules/.pnpm/lodash@3.0.0
./node_modules/.pnpm/lodash@4.0.0
./node_modules/.pnpm/package-a@1.0.0
./node_modules/.pnpm/package-a@1.0.0/node_modules/package-a
./node_modules/.pnpm/package-a@1.0.0/node_modules/lodash     -> .pnpm/package-a@1.0.0/node_modules/lodash@4.0.0
./node_modules/.pnpm/package-b@1.0.0
./node_modules/.pnpm/package-b@1.0.0/node_modules/package-b
./node_modules/.pnpm/package-b@1.0.0/node_modules/lodash     -> .pnpm/package-b@1.0.0/node_modules/lodash@4.0.0
./node_modules/.pnpm/package-c@1.0.0
./node_modules/.pnpm/package-c@1.0.0/node_modules/package-c
./node_modules/.pnpm/package-c@1.0.0/node_modules/lodash     -> .pnpm/package-c@1.0.0/node_modules/lodash@3.0.0
./node_modules/.pnpm/package-d@1.0.0
./node_modules/.pnpm/package-d@1.0.0/node_modules/package-d
./node_modules/.pnpm/package-d@1.0.0/node_modules/lodash     -> .pnpm/package-d@1.0.0/node_modules/lodash@3.0.0
```
如此，依赖软链接的方式，可解决重复依赖安装 (doppelgangers) 的问题，如果一个项目占用 1000 MB，那么使用 pnpm 可能仅占用 800 MB
然而它除此之外，还有一个最大的好处，如果一个项目占用 1000 MB，传统方式十个项目占用 10000 MB，那么使用 pnpm 可能仅占用 3000 MB，而它得益于硬链接。
再借用以上示例，lodash@3.0.0 与 lodash@4.0.0 会生成一个指向全局目录(~/.pnpm-store)的硬链接，如果新项目依赖二者，则可复用存储空间。
```
./node_modules/.pnpm/lodash@3.0.0/node_modules/lodash   -> hardlink
./node_modules/.pnpm/lodash@4.0.0/node_modules/lodash   -> hardlink
```
#### 权限设计中的 RBAC 是指什么
1. 模型是一种常用的权限控制模型，用于管理和控制用户对系统资源的访问权限。在 RBAC 模型中，访问权限是通过角色而不是直接与用户关联来进行管理的。
   用户（User）：用户代表系统中的实体，可以是个人用户或其他应用程序。用户通过被分配角色来获得相应的权限，从而决定其在系统中能够执行的操作。
   角色（Role）：角色代表了一组相关权限的集合，通常与用户的职能、责任或角色相对应。每个角色拥有特定的权限，定义了该角色所能执行的操作。
   权限（Permission）：权限是指用户对系统资源的访问能力。它可以是操作级别的，如读取、写入、删除等，也可以是对象级别的，如访问特定文件或数据库。
2. RBAC工作原理
   把权限赋予角色，再把角色赋予用户，用户就拥有了角色所对应的权限。用户拥有的权限等于他所有的角色持有权限之和。
3. RBAC的几种模型
   默认为RBAC0
- RBAC1 在 RBAC0 的基础上，进行了 角色分层。通过给角色划分等级，每个等级拥有不同的权限，从而实现了更细粒度的权限管理。这种角色的分层让权限的分配更加灵活，可以根据具体需求来调整角色等级和相应的权限。
- RBAC2 RBAC2 在 RBAC0 的基础上增加了 RBAC 的 约束模型。具体来说，这些限制可以分成两类，即静态职责分离（SSD）和动态职责分离（DSD）。通过这些约束模型，RBAC2 能够更好地保证权限的安全性和稳定性。
  静态职责分离（SSD） 主要是对用户、角色和权限三者之间增加了一些限制，例如互斥角色和基数约束。在 SSD 中，一些特定的角色不能被分配给同一个用户。例如，同一用户不能被分配 “管理员” 和 “普通用户” 这两个互斥角色。另外，对于用户拥有的角色数量也有限制，即一个用户拥有的角色是有限的。在一些场景中，例如公司或组织的实际运营中，不同的职位或角色之间具有一定的排他性，不能同时由同一人担任。通过 SSD，我们可以保证这种排他性得以实现。
  动态职责分离（DSD） 主要是在会话和角色之间增加限制。具体来说，DSD 可以动态地约束用户拥有的角色。例如，一个用户可以有多个角色，但是在一次会话中只能激活一个角色。这种动态的约束可以防止用户在会话中同时激活多个角色，从而保证系统的安全性。
- RBAC3 是 RBAC2 和RBAC1的合集，所以它 既包含了角色分层，也包括了可以增加的各种约束。因此，RBAC3是这四种模型中最为全面和复杂的权限管理模型。可以实现更为精细和安全的权限管理。
#### 请问什么是 CICD
CI，Continuous Integration，持续集成。
CD，Continuous Deployment，持续部署。
功能分支提交后，通过 CICD 进行自动化测试、语法检查等，如未通过 CICD，则无法 CodeReview，更无法合并到生产环境分支进行上线
功能分支提交后，通过 CICD 检查 npm 库的风险、检查构建镜像容器的风险等
功能分支提交后，通过 CICD 对当前分支代码构建独立镜像并生成独立的分支环境地址进行测试，如对每一个功能分支生成一个可供测试的地址，一般是 <branch>.dev.shanyue.tech 此种地址
功能分支测试通过后，合并到主分支，自动构建镜像并部署到生成环境 (一般生成环境需要手动触发、自动部署)
CICD 工具
CICD 集成于 CICD 工具及代码托管服务。CICD 有时也可理解为进行 CICD 的构建服务器，而提供 CICD 的服务，如以下产品，将会提供构建服务与 github/gitlab 集成在一起。
jenkins
Travis CI
如果你们公司没有 CICD 基础设置，那么你可以尝试 github 免费的 CICD 服务: github actions。
公司一般以 gitlab CI 作为 CICD 工具，此时需要自建 gitlab Runner 作为构建服务器。
#### 如何进行代码质量检测
eslint代码编写过程中的规范做好限制，提交前运行eslint,并在之前运行单元测试文件，合理的单元测试可以控制代码质量，提交后代码组长审核，之后集成测试。
平时关注一下各个包是否有bug如果有第一时间升级对应的包
#### 请简述下 eslint 的作用
eslint，对代码不仅有风格的校验，更有可读性、安全性、健壮性的校验。
关于校验分号、冒号等，属于风格校验，与个人风格有关，遵循团队标准即可，可商量可妥协。
// 这属于风格校验
```
{
    semi: ["error", "never"];
}
```
与 prettier 不同，eslint 更多是关于代码健壮性校验，试举一例。
Array.prototype.forEach 不要求也不推荐回调函数返回值
Array.prototype.map 回调函数必须返回一个新的值用以映射
当代码不遵守此两条要求时，通过 eslint 以下规则校验，则会报错。此种校验与代码健壮有关，不可商量不可妥协。
// 这属于代码健壮性校验
```
{
    'array-callback-return': ['error', { checkForEach: true }]
}
```
1. Rule
   在 eslint 中，使用 Rule 最为校验代码最小规则单元。
```
{
    rules: {
        semi: ["error", "never"];
        quotes: ["error", "single", { avoidEscape: true }];
    }
}
```
在 eslint 自身，内置大量 rules，比如分号冒号逗号等配置。
2. Plugin
   如 react、typescript、flow 等，需要自制 Rule，此类为 Plugin，他们维护了一系列 Rules。
   在命名时以 eslint-plugin- 开头并发布在 npm 仓库中，而执行的规则以 react/、flow/ 等开头。
3. Config
   在第三方库、公司业务项目中需要配置各种适应自身的规则、插件等，称为 Config。
   作为库发布，在命名时以 eslint-config- 开头，并发布在 npm 仓库中。
   为项目服务，在项目中以 .eslintrc 命名或者置于项目 package.json 中的 eslintConfig 字段中，推荐第二种方案。
   以下是 eslint-config-airbnb 的最外层配置。
```
module.exports = {
extends: [
"eslint-config-airbnb-base",
"./rules/react",
"./rules/react-a11y",
].map(require.resolve),
rules: {},
};
```
在我们公司实际项目中，无需重新造轮子，只需要配置文件中的 extends 继承那些优秀的 eslint-config 即可
#### 测试中 TDD 与 BDD 有什么区别
TDD和BDD有何根本区别？ 答：TDD（测试驱动开发）注重开发者通过编写测试用例来驱动代码的开发，强调单元测试和代码覆盖率；
而BDD（行为驱动开发）更关注系统整体行为，测试用例以自然语言编写，涉及开发者、测试人员和业务分析员的协作，更强调对业务需求的理解

#### JWT 的原理是什么
json web token，由header payload signature组成，使用base64加密
用户登录，将信息在服务器上验证，验证成功服务器根据密钥加密生成jwt，发送请求时携带token，对token进行解密，验证成功返回数据。在服务器存放相同密钥可以实现单点登录
#### git hooks 原理是什么
git 允许在各种操作之前添加一些 hook 脚本，如未正常运行则 git 操作不通过。最出名的还是以下两个
precommit ,prepush
而 hook 脚本置于目录 ~/.git/hooks 中，以可执行文件的形式存在。
在前端工程化中，husky 即通过自定义 core.hooksPath 并将 npm scripts 写入其中的方式来实现此功能。
在 pre-commit 中进行代码风格校验
```
#!/bin/sh
npm run lint
npm run test
```
#### 如何使用 docker 部署前端
假设本地跑起一个前端项目，需要以下步骤，并最终可在 localhost:8080 访问服务。
```
$ npm i
$ npm run build
$ npm start
```
那在 docker 中部署前端，与在本地将如何将项目跑起来步骤大致一致，一个 Dockerfile 如下
```
# 指定 node 版本号，满足宿主环境
FROM node:16-alpine
# 指定工作目录，将代码添加至此
WORKDIR /code
ADD . /code
# 如何将项目跑起来
RUN npm install
RUN npm run build
CMD npm start
# 暴露出运行的端口号，可对外接入服务发现
EXPOSE 8080
```
此时，我们使用 docker build 构建镜像并把它跑起来。
构建镜像
```
$ docker build -t fe-app .
```
运行容器
```
$ docker run -it --rm fe-app
```
恭喜你，能够写出以上的 Dockerfile，这说明你对 Docker 已经有了理解。但其中还有若干的问题，我们对其进行一波优化
使用 node:16 作为基础镜像过于奢侈，占用体积太大，而最终产物 (js/css/html) 无需依赖该镜像。可使用更小的 nginx 镜像做多阶段构建。
多个 RUN 命令，不利于 Docker 的镜像分层存储。可合并为一个 RUN 命令
每次都需要 npm i，可合理利用 Docker 缓存，ADD 命令中内容发生改变将会破坏缓存。可将 package.json 提前移至目标目录，只要 package.json/lockfile 不发生变动，将不会重新 npm i
优化后
```
FROM node:16-alpine as builder
WORKDIR /code
ADD package.json package-lock.json /code/
RUN npm install
ADD . /code
RUN npm run build
# 选择更小体积的基础镜像
FROM nginx:alpine
# 将构建产物移至 nginx 中
COPY --from=builder code/build/ /usr/share/nginx/html/
```
#### babel 的原理
babel 是 JavaScript 编译器，它能让开发者在开发过程中，直接使用各类方言(如 ts jsx)或新的语法特性，而不需要考虑运行环境，因为 babel 可以做到按需转换为低版本支持的代码；babel 内部原理是将 JS 代码转换为 AST，对 AST 应用各种插件进行处理，最终输出编译后的 JS 代码
#### babel 编译流程
解析阶段：babel 默认使用的是 @babel/parser 将代码转换为 AST。解析一般分为两个阶段：词法分析和语法分析。
词法分析：对输入的字符序列做标记化(tokenization)操作
语法分析：处理标记与标记之间的关系，最终形成一颗完整的 AST 结构
转换阶段：babel 使用的是 @babel/traverse 提供的方法对 AST 进行深度优先遍历，调用插件对关注节点的处理函数，按需对 AST 节点进行增删改操作
生成阶段：babel 默认使用的是 @babel/generator 将上一阶段处理后的 AST 转换为代码字符串
#### 在 babel 编译为低版本 ES 时，为何能够编译可选链之类语法，但无法编译 API
API 兼容，则需要引入 core-js 增加垫片代码
#### 什么是 AST，及其应用
AST 是 Abstract Syntax Tree 的简称，是前端工程化绕不过的一个名词。它涉及到工程化诸多环节的应用，比如:
如何将 Typescript 转化为 Javascript (typescript)
如何将 SASS/LESS 转化为 CSS (sass/less)
如何将 ES6+ 转化为 ES5 (babel)
如何将 Javascript 代码进行格式化 (eslint/prettier)
如何识别 React 项目中的 JSX (babel)
GraphQL、MDX、Vue SFC 等等
而在语言转换的过程中，实质上就是对其 AST 的操作，核心步骤就是 AST 三步走
Code -> AST (Parse)
AST -> AST (Transform)
AST -> Code (Generate)
1. AST 的生成的生成
   AST 的生成这一步骤被称为解析(Parser)，而该步骤也有两个阶段: 词法分析(Lexical Analysis)和语法分析(Syntactic Analysis)
   1.1 词法分析 (Lexical Analysis)：词法分析用以将代码转化为 Token 流，维护一个关于 Token 的数组
   词法分析后的 Token 流也有诸多应用，如:
   代码检查，如 eslint 判断是否以分号结尾，判断是否含有分号的 token
   语法高亮，如 highlight/prism 使之代码高亮
   模板语法，如 ejs 等模板也离不开
   1.2 语法分析 (Syntactic Analysis)：语法分析将 Token 流转化为结构化的 AST，方便操作
#### core-js 是做什么用的？
core-js(opens new window) 是关于 ES 标准最出名的 polyfill，polyfill 意指当浏览器不支持某一最新 API 时，它将帮你实现，中文叫做垫片。
由于垫片的存在，打包后体积便会增加，所需支持的浏览器版本越高，垫片越少，体积就会越小。
而 core-js 的伟大之处是它包含了所有 ES6+ 的 polyfill，并集成在 babel 等编译工具之中
core-js 已集成到了 babel 之中，你可以使用 @babel/preset-env 或者 @babel/polyfill 进行配置，详见文档 core-js(opens new window)。通过配置，babel 编译代码后将会自动包含所需的 polyfill
